---
title: "Econ 293 Final Project: Data Summary Statistics"
author: 
- Chris Lin, Joseph Son
- (clin17@stanford.edu, joeson@stanford.edu)
date: '`r Sys.Date()`'
output: pdf_document
---

```{r setup, warning=FALSE, message=FALSE}
library(dplyr)
library(kableExtra)
library(sandwich)
library(ggplot2)
```

```{r load_data, warning=FALSE, message=FALSE}
source("load-data.R")
```

```{r summary_tab, warning=FALSE, message=FALSE}
get_mean_sd <- function(x) {
  return(paste0(signif(mean(x), 3), " (", signif(sd(x), 3), ")"))
}

get_N_prop <- function(x) {
  N <- sum(x)
  prop <- sum(x) / length(x)
  return(paste0(format(N, big.mark = ","), " (", signif(prop * 100, 3), "%)"))
}

# Summary statistics for covariates by outcome variable Y
stats_by_y <- function(dataset, features) {
  y0 <- dataset %>% dplyr::filter(Y == 0)
  y1 <- dataset %>% dplyr::filter(Y == 1)
  
  y0_colname <- paste0("No donation (N = ", format(nrow(y0), big.mark = ","), ")")
  y1_colname <- paste0("Donation (N = ", format(nrow(y1), big.mark = ","), ")")
  
  df_lst <- list()
  for (feature in features) {
    if (length(unique(dataset[ , feature])) > 2) {
      y0_stat <- get_mean_sd(y0[, feature])
      y1_stat <- get_mean_sd(y1[, feature])
    } else {
      y0_stat <- get_N_prop(y0[ , feature])
      y1_stat <- get_N_prop(y1[, feature])
    }
    summary_df <- data.frame("feature" = feature, 
                             "y0_stat" = y0_stat, 
                             "y1_stat" = y1_stat, 
                             stringsAsFactors = FALSE)
    colnames(summary_df)[2:3] <- c(y0_colname, y1_colname)
    df_lst[[feature]] <- summary_df
  }
  return(Reduce(rbind, df_lst))
}

# Generate summary stats for each treatment/control group
treat_subgrps <- lapply(0:3, function(grp) df %>% filter(treatment_lvl == grp))
summary_subgrps <- lapply(treat_subgrps, function(df) stats_by_y(df, covariate_names))
summary_tab <- Reduce(cbind, summary_subgrps)

# Remove unnecessary columns
summary_tab <- summary_tab[ , -which(colnames(summary_tab) == "feature")[-1]]

# Rename
colnames(summary_tab)[1] <- "Covariate"
summary_tab$Covariate <- covariate_descps

# Format column group names for treatment/control group
grp_N <- sapply(treat_subgrps, function(df) format(nrow(df), big.mark = ","))
grp_names <- paste0(c("Control", "Treatment 1:1", "Treatment 2:1", "Treatment 3:1"), 
                    " (N = ", grp_N, ")")
summary_tab_header <- c(1, rep(2, length(treat_subgrps)))
names(summary_tab_header) <- c(" ", grp_names)


kable(summary_tab, "latex", booktabs = T, 
      caption = "Summary statstics by treatment and outcome. Mean (standard deviation) is 
      reported for each continuous covariate. Count (percentage) is reported for each 
      categorical covaraite.") %>% 
  add_header_above(summary_tab_header) %>%
  landscape()
```

```{r load_helpers, warning=FALSE, message=FALSE}
source("helpers.R")
```

```{r ATE_calculations, warning=FALSE, message=FALSE}
# Convert to binary treatment
df1 <- convert_df(df, 0, 1)
df2 <- convert_df(df, 0, 2)
df3 <- convert_df(df, 0, 3)

# Calculate RCT baseline
tauhat_rct1 <- difference_in_means(df1)
tauhat_rct2 <- difference_in_means(df2)
tauhat_rct3 <- difference_in_means(df3)

# ATE using Direct Conditional Regression with OLS
tauhat_ols1 <- ate_condmean_ols(df1)
tauhat_ols2 <- ate_condmean_ols(df2)
tauhat_ols3 <- ate_condmean_ols(df3)

# Calculate propensity score for use in IPW and AIPW
p1 <- prop_score(df1)
p2 <- prop_score(df2)
p3 <- prop_score(df3)

# ATE using IPW
tauhat_logistic_ipw1 <- ipw(df1, p1)
tauhat_logistic_ipw2 <- ipw(df2, p2)
tauhat_logistic_ipw3 <- ipw(df3, p3)

# ATE using AIPW
tauhat_logistic_aipw1 <- aipw_ols(df1, p1)
tauhat_logistic_aipw2 <- aipw_ols(df2, p2)
tauhat_logistic_aipw3 <- aipw_ols(df3, p3)
```

```{r calibration_plots, warning=FALSE, message=FALSE}
plot_calibration(p1, df1$W)
plot_calibration(p2, df2$W)
plot_calibration(p3, df3$W)
```

```{r results_table, warning=FALSE, message=FALSE}
all_estimators = rbind(
  RCT_gold_standard_1 = tauhat_rct1,
  RCT_gold_standard_2 = tauhat_rct2,
  RCT_gold_standard_3 = tauhat_rct3,
  linear_regression_1 = tauhat_ols1,
  linear_regression_2 = tauhat_ols2,
  linear_regression_3 = tauhat_ols3,
  IPW_logistic_1 = tauhat_logistic_ipw1,
  IPW_logistic_2 = tauhat_logistic_ipw2,
  IPW_logistic_3 = tauhat_logistic_ipw3,
  AIPW_logistic_1 = tauhat_logistic_aipw1,
  AIPW_logistic_2 = tauhat_logistic_aipw2,
  AIPW_logistic_3 = tauhat_logistic_aipw3
)
all_estimators <- data.frame(all_estimators)
all_estimators <- add_rownames(all_estimators, "Estimator")
all_estimators$treatment_lvl <- substr(all_estimators$Estimator, nchar(all_estimators$Estimator), nchar(all_estimators$Estimator))
all_estimators

f <- ggplot(all_estimators, aes(x = Estimator, y = ATE, ymin = lower_ci, ymax = upper_ci))
f + geom_crossbar(aes(color = treatment_lvl),
                  position = position_dodge(1)) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

TO-DO:
- how to automate the way we calculate propensity score and another regression fn instead of OLS
- sensitivity with data reduction